{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpejAPfmbVx8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRC2rL_gYIAi",
        "outputId": "353fc355-dcfd-4c1c-c05b-76b69d6f56b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
            "      - Validating: \u001b[32mOK\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn-46qlzbVx8"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# from tensorflow.keras.layers import TextVectorization\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj_wNt9QbVx9"
      },
      "source": [
        "## Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPQhVmsDbVx9"
      },
      "outputs": [],
      "source": [
        "# TODO in colab (last)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as4siLw2bVx-"
      },
      "source": [
        "## Parsing the data\n",
        "\n",
        "We prepend the token \"[start]\" and we append the token \"[end]\" to each Romanian sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UissrYg-bVx-"
      },
      "outputs": [],
      "source": [
        "with open('europarl-v7.ro-en.en') as f:\n",
        "    en_lines = f.read().split(\"\\n\")[:-1]\n",
        "with open('europarl-v7.ro-en.ro') as f:\n",
        "    ro_lines = f.read().split(\"\\n\")[:-1]    \n",
        "    \n",
        "text_pairs = []\n",
        "assert len(en_lines) == len(ro_lines)\n",
        "for i in range(len(en_lines)):\n",
        "    en = en_lines[i]\n",
        "    ro = ro_lines[i]\n",
        "    ro = \"[start] \" + ro + \" [end]\"\n",
        "    text_pairs.append((en, ro))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mli-vWepbVx_"
      },
      "source": [
        "Here's what our sentence pairs look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxDg1KHQbVx_",
        "outputId": "6c5f2e3c-1f03-4b09-f05e-1dadefd9eeb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('However, I believe that there is a great deal of untapped potential for boosting trade between both regions.', '[start] Consider, însă, că există un mare potenţial nevalorificat de creştere a schimburilor comerciale dintre cele două regiuni. [end]')\n",
            "('When, for example, a constitutional court has no jurisdiction in budgetary and taxation matters, this constitutes a restriction in the separation of powers and is unquestionably a dubious situation.', '[start] De exemplu, atunci când o curte constituţională nu are jurisdicţie în aspecte bugetare şi de fiscalitate, acest lucru reprezintă o restricţie a separării puterilor în stat şi cu, siguranţă, este o situaţie dubioasă. [end]')\n",
            "('In fact, the difference in prices between the beginning and the end of the food supply chain can be as high as a one to five ratio and, even if the liberals still refuse to admit it, the problems of the market need tackling to ensure reasonable prices for consumers and decent revenues for farmers.', '[start] De fapt, diferenţa de preţuri dintre începutul şi sfârşitul lanţului de aprovizionare cu alimente poate ajunge chiar la un raport de unu la cinci şi, chiar dacă liberalii refuză în continuare să admită acest lucru, problemele pieţei trebuie să fie abordate pentru a se garanta preţuri rezonabile pentru consumatori şi venituri decente pentru agricultori. [end]')\n",
            "('I voted in favour of the motion for a resolution on the waste crisis in Campania, long-standing problem that it is, because I do not believe that the responsibility for the current situation can be attributed to one government alone.', '[start] Am votat în favoarea propunerii de rezoluție privind criza deșeurilor din Campania, problemă care persistă de mult timp, deoarece nu consider că responsabilitatea pentru situația actuală poate fi atribuită numai unui singur guvern. [end]')\n",
            "('We often discuss how to encourage this very group of businesses to introduce innovations and patent their own inventions, particularly in the Committee on Industry, Research and Energy.', '[start] Discutăm adesea despre modalităţile prin care putem încuraja exact acest grup de întreprinderi să introducă inovaţii şi să-şi breveteze propriile inovaţii, mai ales în Comisia pentru industrie, cercetare şi energie. [end]')\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu5F50WJbVx_"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AX_hik_bVyA",
        "outputId": "3519e35f-1fbf-4980-ffbe-b6f8ca232cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "399375 total pairs\n",
            "279563 training pairs\n",
            "59906 validation pairs\n",
            "59906 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.Random(4).shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TfeBiQgbVyA"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Romanian),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGySkF1qbVyA"
      },
      "outputs": [],
      "source": [
        "# strip_chars = string.punctuation\n",
        "# strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "# strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# def custom_standardization(input_string):\n",
        "#     lowercase = tf.strings.lower(input_string)\n",
        "#     return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "ro_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length+1,\n",
        ")\n",
        "# ro_vectorization = TextVectorization(\n",
        "#     max_tokens=vocab_size,\n",
        "#     output_mode=\"int\",\n",
        "#     output_sequence_length=sequence_length + 1,\n",
        "#     standardize=custom_standardization,\n",
        "# )\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_ro_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "ro_vectorization.adapt(train_ro_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn6ckt74bVyB"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEsn5dkYbVyB",
        "outputId": "0b53cb51-6c0f-40dd-8b2e-437547ebcc7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function format_dataset at 0x7fb609782280> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function format_dataset at 0x7fb609782280> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ],
      "source": [
        "def format_dataset(eng, ro):\n",
        "    eng = eng_vectorization(eng)\n",
        "    ro = ro_vectorization(ro)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ro[:, :-1],}, ro[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ro_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ro_texts = list(ro_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ro_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vLKNA6bVyB"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fDEwKtobVyB",
        "outputId": "361a0321-b79d-4fae-a4a3-6d1f379e5285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHCS4KmIbVyC"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aEAOi5ibVyC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wllSHutEbVyC"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmWmM0zDbVyD",
        "outputId": "0444793c-e4ef-441a-bd4b-d068c1b28092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method PositionalEmbedding.call of <__main__.PositionalEmbedding object at 0x7fb60977d910>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method PositionalEmbedding.call of <__main__.PositionalEmbedding object at 0x7fb60977d910>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x7fb458d2db80>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method TransformerEncoder.call of <__main__.TransformerEncoder object at 0x7fb458d2db80>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method TransformerDecoder.call of <__main__.TransformerDecoder object at 0x7fb458c119a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method TransformerDecoder.call of <__main__.TransformerDecoder object at 0x7fb458c119a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module 'gast' has no attribute 'Index'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3kOyDxKYIAq"
      },
      "outputs": [],
      "source": [
        "# from transformers import MarianTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# text = 'Рада познакомиться'\n",
        "# mname = 'Helsinki-NLP/opus-mt-ru-en'\n",
        "# tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(mname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53WFf3gcbVyD"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v7srC3NbVyD",
        "outputId": "20bbd3a4-5720-43f5-cf84-51cc226a79ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding (Positiona (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder (Transforme (None, None, 256)    3155456     positional_embedding[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PositionalEmbedding has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/40\n",
            "4369/4369 [==============================] - 220s 50ms/step - loss: 4.6082 - accuracy: 0.2649 - val_loss: 3.2199 - val_accuracy: 0.4476\n",
            "Epoch 2/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 3.2469 - accuracy: 0.4549 - val_loss: 2.8732 - val_accuracy: 0.5072\n",
            "Epoch 3/40\n",
            "4369/4369 [==============================] - 217s 50ms/step - loss: 2.9538 - accuracy: 0.5029 - val_loss: 2.7379 - val_accuracy: 0.5296\n",
            "Epoch 4/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.8328 - accuracy: 0.5254 - val_loss: 2.6682 - val_accuracy: 0.5400\n",
            "Epoch 5/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.7530 - accuracy: 0.5401 - val_loss: 2.6152 - val_accuracy: 0.5495\n",
            "Epoch 6/40\n",
            "4369/4369 [==============================] - 216s 49ms/step - loss: 2.6942 - accuracy: 0.5509 - val_loss: 2.5845 - val_accuracy: 0.5560\n",
            "Epoch 7/40\n",
            "4369/4369 [==============================] - 218s 50ms/step - loss: 2.6446 - accuracy: 0.5595 - val_loss: 2.5788 - val_accuracy: 0.5567\n",
            "Epoch 8/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.6016 - accuracy: 0.5668 - val_loss: 2.5528 - val_accuracy: 0.5625\n",
            "Epoch 9/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.5641 - accuracy: 0.5733 - val_loss: 2.5508 - val_accuracy: 0.5635\n",
            "Epoch 10/40\n",
            "4369/4369 [==============================] - 216s 49ms/step - loss: 2.5304 - accuracy: 0.5790 - val_loss: 2.5494 - val_accuracy: 0.5633\n",
            "Epoch 11/40\n",
            "4369/4369 [==============================] - 217s 50ms/step - loss: 2.5015 - accuracy: 0.5845 - val_loss: 2.5486 - val_accuracy: 0.5654\n",
            "Epoch 12/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.4716 - accuracy: 0.5896 - val_loss: 2.5556 - val_accuracy: 0.5650\n",
            "Epoch 13/40\n",
            "4369/4369 [==============================] - 216s 50ms/step - loss: 2.4457 - accuracy: 0.5942 - val_loss: 2.5385 - val_accuracy: 0.5673\n",
            "Epoch 14/40\n",
            "4369/4369 [==============================] - 216s 49ms/step - loss: 2.4205 - accuracy: 0.5984 - val_loss: 2.5563 - val_accuracy: 0.5666\n",
            "Epoch 15/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.3992 - accuracy: 0.6019 - val_loss: 2.5495 - val_accuracy: 0.5674\n",
            "Epoch 16/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.3798 - accuracy: 0.6052 - val_loss: 2.5581 - val_accuracy: 0.5682\n",
            "Epoch 17/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.3591 - accuracy: 0.6085 - val_loss: 2.5700 - val_accuracy: 0.5679\n",
            "Epoch 18/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.3405 - accuracy: 0.6119 - val_loss: 2.5777 - val_accuracy: 0.5684\n",
            "Epoch 19/40\n",
            "4369/4369 [==============================] - 213s 49ms/step - loss: 2.3237 - accuracy: 0.6148 - val_loss: 2.5815 - val_accuracy: 0.5681\n",
            "Epoch 20/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.3090 - accuracy: 0.6173 - val_loss: 2.5883 - val_accuracy: 0.5678\n",
            "Epoch 21/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.2955 - accuracy: 0.6198 - val_loss: 2.6136 - val_accuracy: 0.5655\n",
            "Epoch 22/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.2830 - accuracy: 0.6222 - val_loss: 2.6042 - val_accuracy: 0.5677\n",
            "Epoch 23/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.2713 - accuracy: 0.6241 - val_loss: 2.6419 - val_accuracy: 0.5630\n",
            "Epoch 24/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.2616 - accuracy: 0.6260 - val_loss: 2.6206 - val_accuracy: 0.5668\n",
            "Epoch 25/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.2537 - accuracy: 0.6274 - val_loss: 2.6870 - val_accuracy: 0.5611\n",
            "Epoch 26/40\n",
            "4369/4369 [==============================] - 217s 50ms/step - loss: 2.2485 - accuracy: 0.6281 - val_loss: 2.6311 - val_accuracy: 0.5647\n",
            "Epoch 27/40\n",
            "4369/4369 [==============================] - 215s 49ms/step - loss: 2.2405 - accuracy: 0.6295 - val_loss: 2.6488 - val_accuracy: 0.5645\n",
            "Epoch 28/40\n",
            "4369/4369 [==============================] - 217s 50ms/step - loss: 2.2328 - accuracy: 0.6309 - val_loss: 2.6926 - val_accuracy: 0.5571\n",
            "Epoch 29/40\n",
            "4369/4369 [==============================] - 214s 49ms/step - loss: 2.2278 - accuracy: 0.6321 - val_loss: 2.6552 - val_accuracy: 0.5631\n",
            "Epoch 30/40\n",
            "4369/4369 [==============================] - 218s 50ms/step - loss: 2.2223 - accuracy: 0.6334 - val_loss: 2.6670 - val_accuracy: 0.5641\n",
            "Epoch 31/40\n",
            "4369/4369 [==============================] - 217s 50ms/step - loss: 2.2109 - accuracy: 0.6353 - val_loss: 2.6800 - val_accuracy: 0.5612\n",
            "Epoch 32/40\n",
            "4369/4369 [==============================] - 218s 50ms/step - loss: 2.2051 - accuracy: 0.6362 - val_loss: 2.6991 - val_accuracy: 0.5624\n",
            "Epoch 33/40\n",
            "4369/4369 [==============================] - 216s 49ms/step - loss: 2.1936 - accuracy: 0.6382 - val_loss: 2.7112 - val_accuracy: 0.5615\n",
            "Epoch 34/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1825 - accuracy: 0.6403 - val_loss: 2.7195 - val_accuracy: 0.5594\n",
            "Epoch 35/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1772 - accuracy: 0.6415 - val_loss: 2.7466 - val_accuracy: 0.5533\n",
            "Epoch 36/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1705 - accuracy: 0.6427 - val_loss: 2.7576 - val_accuracy: 0.5525\n",
            "Epoch 37/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1695 - accuracy: 0.6428 - val_loss: 2.7272 - val_accuracy: 0.5605\n",
            "Epoch 38/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1695 - accuracy: 0.6428 - val_loss: 2.7337 - val_accuracy: 0.5597\n",
            "Epoch 39/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1574 - accuracy: 0.6452 - val_loss: 2.7256 - val_accuracy: 0.5588\n",
            "Epoch 40/40\n",
            "4369/4369 [==============================] - 211s 48ms/step - loss: 2.1541 - accuracy: 0.6456 - val_loss: 2.7603 - val_accuracy: 0.5584\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb458674be0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 40  # This should be at least 30 for convergence\n",
        "\n",
        "checkpoint_filepath = 'transformer.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard()\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[model_checkpoint_callback, tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIq1AimubVyD"
      },
      "source": [
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new English sentences.\n",
        "We simply feed into the model the vectorized English sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5agt1runbVyD",
        "outputId": "5cca37ea-72c2-451c-d13f-0a2c799a7e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clearly, the crazy world of finance is today speculating on the food markets, without ever wanting to touch the goods themselves, which are constantly bought and sold. [start] În mod evident lumea [UNK] a [UNK] astăzi pe pieţele alimentare fără a se dori să [UNK] produsele [UNK] în\n",
            "This standard also needs to look to the future. [start] acest standard trebuie să [UNK] viitorul end             \n",
            "It is unfortunate, however, that the motion also stands behind the Basel II provisions which, we know from experience, have led to the flow of capital to small and medium-sized businesses practically running dry. [start] cu toate acestea este regretabil faptul că propunerea se află în spatele [UNK] de fapt acest lucru este regretabil că\n",
            "Rather, investing in a greater number of cross-border connections would more effectively reduce dependence on one or more third countries in the long term. [start] mai degrabă să [UNK] o serie de [UNK] transfrontaliere ar reduce mai mult dependenţa de un ţară sau de ţări\n",
            "Mr President, ladies and gentlemen, we did indeed experience some very tough negotiations, Mr Schwab, as opinions were very divided at the start of discussions. [start] dle președinte doamnelor și domnilor am avut întradevăr o [UNK] foarte dificilă dle schwab după cum au fost [UNK] [UNK]\n",
            "They argue for flexible implementation of the Stability Pact, so that an unwelcome austerity cure can be avoided. [start] aceştia sunt [UNK] pentru punerea în aplicare a pactului de stabilitate astfel încât [UNK] să fie [UNK] [UNK] end \n",
            "I hope that the Council will demonstrate sufficient flexibility so that this legislation can be adopted on time before the start of the season in which bluetongue can break out. [start] sper că consiliul va demonstra destul de necesar astfel încât această legislație să fie adoptată pe această legislație în acest\n",
            "Therefore, I have taken specific steps to encourage the industry to bring a standard charger onto the market. [start] prin urmare am luat măsuri specifice pentru a încuraja industria să [UNK] un [UNK] standard pe piață end  \n",
            "We expressed our opinions to reassure the people who sent us here that we are on the alert for any infringements of their rights. [start] neam exprimat opiniile noastre pentru a asigura [UNK] oamenilor pe noi cei care ne [UNK] aici suntem în ceea ce\n",
            "(The sitting was suspended at 20:30 and resumed at 21:00) [start] Şedinţa a fost suspendată la ora de [UNK] şi reluată la ora în 2 end     \n",
            "The debate is closed. [start] dezbaterea a fost închisă end               \n",
            "(The President cut off the speaker) [start] preşedintele a întrerupto pe vorbitoare end              \n",
            "Our own experience in Ireland has shown how liberalisation and resulting privatisation have not provided solutions to any problems in the energy sector. [start] experiența noastră din irlanda a demonstrat cum care liberalizarea și [UNK] nu a oferit soluţii la orice probleme în această\n",
            "It does not speak with one coherent voice, but with many voices. [start] nu este vorba de o voce clară [UNK] dar multe [UNK] end        \n",
            "Madam President, Commissioner, ladies and gentlemen, I would like to thank all of the political groups and everyone who has spoken for the support and the constructive tone of their speeches. [start] doamnă preşedintă domnule comisar doamnelor şi domnilor aş dori să mulţumesc tuturor grupurilor politice şi tuturor celor care au [UNK]\n",
            "Stateless people are a separate issue and should be encouraged, using all means available, to apply for citizenship in their host country. [start] [UNK] oameni reprezintă o problemă și ar trebui [UNK] toate mijloacele disponibile pentru a aplica în vederea [UNK] în [UNK]\n",
            "The debate is closed. [start] dezbaterea a fost închisă end               \n",
            "This subject has a profoundly foreign policy dimension. [start] acest subiect are o politică externă foarte [UNK] end           \n",
            "The strength of Christine Lagarde's candidacy is not that she is a European, but that she is a hugely competent individual who has shown remarkable leadership qualities throughout the financial crisis. [start] [UNK] [UNK] [UNK] nu este că este o [UNK] europeană dar că este o [UNK] [UNK] [UNK] [UNK] end \n",
            "Given the importance of an integrated energy policy, not only in combating climate change and reducing CO2 emissions, but also in ensuring efficiency and less energy dependence within Europe, communication and transmission of information about investments and energy infrastructure projects is crucial. [start] având în vedere importanţa politicii energetice integrate nu numai în combaterea schimbărilor climatice şi reducerea emisiilor de co2 ci şi\n",
            "Women also perform the lower skilled jobs. [start] de asemenea femeile au locuri de muncă sigure end           \n",
            "If, during the hearings in Parliament, we are of the opinion that the allocation of the portfolios does not fully meet these objectives and we make proposals for changing the portfolios, are you prepared in principle to address our objections and to make changes? [start] dacă în timpul [UNK] din parlament suntem de părere că alocarea [UNK] nu are o abordare complet în această privinţă\n",
            "However, that alone will not be enough. [start] cu toate acestea numai că nu va fi destul end          \n",
            "I voted for this report because I essentially share the rapporteur's concerns, particularly as regards amendments pertaining to the following key issues: 1) the general aim of this proposal should be linked to the promotion of a high level of employment, the guarantee of adequate social protection and the fight against social exclusion; 2) rules put forward to ensure improvements in national budgetary frameworks should be established in the context of the European Semester for policy coordination; 3) the requirements for national budgetary frameworks should not only ensure that Member States' fiscal planning is based on realistic forecasts, but should also ensure that appropriate attention is given to the sustainability of their respective social protection systems, including health care and pension systems; and, finally, 4) the requirements for national budgetary frameworks should also be designed in such a way as to encourage Member States to achieve the EU's growth and jobs objectives. [start] am votat în favoarea acestui raport deoarece sunt în mod deosebit preocupările raportorului în ceea ce priveşte amendamentele legate de\n",
            "If we add yet another programme, then we will make the whole area difficult to get to grips with. [start] dacă [UNK] încă un program atunci vom face întreaga zonă dificilă va avea [UNK] end     \n",
            "I fully support the formation of the European External Action Service and value highly the efforts of Elmar Brok and other MEPs who have managed to successfully balance the original draft presented by the High Representative. [start] sprijin pe deplin formării serviciului european pentru acţiune externă şi valoarea [UNK] [UNK] [UNK] [UNK] şi [UNK] end  \n",
            "I also believe that the new President of the ECB will implement a culture of honesty and rigour, as well as helping to set out robust and consistent economic policy, sending a clear signal of confidence to the international markets. [start] de asemenea cred că noul preşedinte al bce va pune în aplicare o cultură de în europa end  \n",
            "While I share the wish of the European Parliament to support economic growth through the EU programmes, we should also take into account the amount of payments that can be reasonably executed without undermining sound financial management. [start] deşi văd că [UNK] parlamentului european pentru a sprijini creşterea economică prin programele ue ar trebui de asemenea să [UNK]\n",
            "I believe that a clearer picture will emerge only when it is patently obvious what is going to happen with Turkey's accession to the EU and what status Russia will have in relation to the Union. [start] cred că o imagine mai clară va [UNK] va [UNK] ceea ce va avea loc este clar ceea ce se\n",
            "The rapporteur himself realises the weaknesses of the agreement, setting out a long list of concerns that it does not explicitly address. [start] raportorul îşi [UNK] [UNK] punctele slabe ale acordului [UNK] de mult timp și se referă la faptul că nu numai\n"
          ]
        }
      ],
      "source": [
        "ro_vocab = ro_vectorization.get_vocabulary()\n",
        "ro_index_lookup = dict(zip(range(len(ro_vocab)), ro_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ro_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ro_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence, translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRwI05jPYIAr",
        "outputId": "6f2fc632-517b-476f-8933-3bfb39c749ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 53355/59906 [3:36:18<26:51,  4.07it/s]  "
          ]
        }
      ],
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "test_ro_texts = [pair[1] for pair in test_pairs]\n",
        "pred_ro_texts = []\n",
        "# tqdm._instances.clear()\n",
        "for i in tqdm(range(len(test_eng_texts))):\n",
        "    pred_ro_text = decode_sequence(test_eng_texts[i])\n",
        "    pred_ro_texts.append(pred_ro_text)\n",
        "\n",
        "score = corpus_bleu(test_ro_texts, pred_ro_texts)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX4jWwhzYIAr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "nmt_transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}